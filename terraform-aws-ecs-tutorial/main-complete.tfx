# * Step 1 - Give your project a unique name. You must use hyphens for
# * spaces. Good examples are using your name like "nimit-shah".
locals { example = "TODO_REPLACE_WITH_YOUR_NAME" }

# * Step 2 - Setup.
terraform {
	required_version = "~> 1.1"

	required_providers {
		aws = {
			source  = "hashicorp/aws"
			version = "~> 4.56"
		}
		docker = {
			source  = "kreuzwerker/docker"
			version = "~> 3.0"
		}
	}
}

locals {
	container_name = "hello-world-container"
	container_port = 8080 # ! Must be same port from our Dockerfile that we EXPOSE
}


# * These variables are autoloaded from ./aws.auto.tfvars.json
variable "AWS_ACCESS_KEY_ID" { type = string }
variable "AWS_SECRET_ACCESS_KEY" { type = string }
provider "aws" {
	access_key = var.AWS_ACCESS_KEY_ID
	region = "ca-central-1"
	secret_key = var.AWS_SECRET_ACCESS_KEY


	default_tags {
		tags = { example = local.example }
	}
}

# * Give Docker permission to pusher Docker Images to AWS.
data "aws_caller_identity" "this" {}
data "aws_ecr_authorization_token" "this" {}
data "aws_region" "this" {}
locals { ecr_address = format("%v.dkr.ecr.%v.amazonaws.com", data.aws_caller_identity.this.account_id, data.aws_region.this.name) }
provider "docker" {
	registry_auth {
		address  = local.ecr_address
		password = data.aws_ecr_authorization_token.this.password
		username = data.aws_ecr_authorization_token.this.user_name
	}
}

# * Step 3 - Build and push our Docker Image.
# * Create an ECR Repository that we will push our Docker Image to later.
resource "aws_ecr_repository" "this" {
	force_delete = true # Delete the repository even if it contains images
	name = local.example
}

# * Give our Repository a policy to delete old Images to keep storage costs down.
resource "aws_ecr_lifecycle_policy" "this" {
	repository = resource.aws_ecr_repository.this.name
	policy = jsonencode({
		rules = [{
			action = { type = "expire" }
			description = "Delete all images except a handful of the newest images"
			rulePriority = 1
			selection = {
				countNumber = 3
				countType = "imageCountMoreThan"
				tagStatus = "any"
			}
		}]
	})
}

# * Build our Image locally with the appropriate name to push our Image
# * to our Repository in AWS.
resource "docker_image" "this" {
	# Generate an image name that Docker will publish to our ECR instance like:
	# 123456789.dkr.ecr.ca-central-1.amazonaws.com/abcdefghijk:2023-03-21T12-34-56
	# {{123456789.dkr.ecr.ca-central-1.amazonaws.com}}/{{abcdefghijk}}:{{2023-03-21T12-34-56}}
	# {{%v}}/{{%v}}:{{%v}}
	name = format("%v/%v:%v", local.ecr_address, resource.aws_ecr_repository.this.id, formatdate("YYYY-MM-DD'T'hh-mm-ss", timestamp()))

	build { context = "." }
}

# * Push our Image to our Repository.
resource "docker_registry_image" "this" {
	keep_remotely = true # Do not delete the old image when a new image is built
	name = resource.docker_image.this.name
}

# * Step 4 - Setting up our networks to accept and make requests to the internet.
# * AWS requires us to use multiple Availability Zones and we only want to use
# * ones the are up and running so we find those ones here.
data "aws_availability_zones" "available" { state = "available" }
module "vpc" {
	source = "terraform-aws-modules/vpc/aws"
	version = "~> 3.19.0"

	azs = slice(data.aws_availability_zones.available.names, 0, 2) # Span subnetworks across multiple avalibility zones
	cidr = "10.0.0.0/16"
	create_igw = true # Expose public subnetworks to the Internet
	enable_nat_gateway = true # Hide private subnetworks behind NAT Gateway
	private_subnets = ["10.0.1.0/24", "10.0.2.0/24"]
	public_subnets = ["10.0.101.0/24", "10.0.102.0/24"]
}

# * Step 5 - Setting up our Application Load Balancers to manage incoming internet traffic.
# * Create an AWS Application Load Balancer that accepts HTTP requests (on port 80) and
# * forwards those requests to port 8080 (our container port) on the VPC where we will
# * eventually run our container.
module "alb" {
	source  = "terraform-aws-modules/alb/aws"
	version = "~> 8.4.0"

	load_balancer_type = "application"
	security_groups = [module.vpc.default_security_group_id]
	subnets = module.vpc.public_subnets
	vpc_id = module.vpc.vpc_id

	security_group_rules = {
		ingress_all_http = {
			type        = "ingress"
			from_port   = 80
			to_port     = 80
			protocol    = "TCP"
			description = "HTTP web traffic"
			cidr_blocks = ["0.0.0.0/0"]
		}
		egress_all = {
			type        = "egress"
			from_port   = 0
			to_port     = 0
			protocol    = "-1"
			cidr_blocks = ["0.0.0.0/0"]
		}
	}

	http_tcp_listeners = [
		{
			# ! Defaults to "forward" action for "target group"
			# ! at index = 0 in "the target_groups" input below.
			port               = 80
			protocol           = "HTTP"
			target_group_index = 0
		}
	]

	target_groups = [
		{
			backend_port         = local.container_port
			backend_protocol     = "HTTP"
			target_type          = "ip"
		}
	]
}

# * Step 6 - Create our ECS Cluster that our ECS Service will run inside of.
resource "aws_ecs_cluster" "this" { name = "${local.example}-cluster" }
resource "aws_ecs_cluster_capacity_providers" "this" {
	capacity_providers = ["FARGATE"]
	cluster_name = resource.aws_ecs_cluster.this.name
}

# * Step 7 - Create our AWS ECS Task Definition which tells ECS how to run our
# * container (from our Docker Image).
data "aws_iam_policy_document" "this" {
	version = "2012-10-17"

	statement {
		actions = ["sts:AssumeRole"]
		effect = "Allow"

		principals {
			identifiers = ["ecs-tasks.amazonaws.com"]
			type = "Service"
		}
	}
}
resource "aws_iam_role" "this" { assume_role_policy = data.aws_iam_policy_document.this.json }
resource "aws_iam_role_policy_attachment" "default" {
	policy_arn  = "arn:aws:iam::aws:policy/service-role/AmazonECSTaskExecutionRolePolicy"
	role = resource.aws_iam_role.this.name
}
resource "aws_ecs_task_definition" "this" {
	container_definitions = jsonencode([{
		environment: [
			{ name = "MY_INPUT_ENV_VAR", value = "terraform-modified-env-var" }
		],
		essential = true,
		image = resource.docker_registry_image.this.name,
		name = local.container_name,
		portMappings = [{ containerPort = local.container_port }],
	}])
	cpu = 256
	execution_role_arn = resource.aws_iam_role.this.arn
	family = "family-of-${local.example}-tasks"
	memory = 512
	network_mode = "awsvpc"
	requires_compatibilities = ["FARGATE"]
}

# * Step 8 - Run our application.
resource "aws_ecs_service" "this" {
	cluster = resource.aws_ecs_cluster.this.id
	desired_count = 1
	launch_type = "FARGATE"
	name = "${local.example}-service"
	task_definition = resource.aws_ecs_task_definition.this.arn

	load_balancer {
		container_name = local.container_name
		container_port = local.container_port
		target_group_arn = module.alb.target_group_arns[0]
	}

	network_configuration {
		security_groups = [module.vpc.default_security_group_id]
		subnets = module.vpc.private_subnets
	}
}

# * Step 9 - See our application working.
# * Output the URL of our Application Load Balancer so that we can connect to
# * our application running inside  ECS once it is up and running.
output "url" { value = "http://${module.alb.lb_dns_name}" }
